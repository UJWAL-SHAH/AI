{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "J078_Neural_Network_Module_Traffic_Problem.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOYYYVMVqejH1i7RcJf8+pu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UJWAL-SHAH/AI/blob/master/edx_Project/Neural_Network_Module/J078_Neural_Network_Module_Traffic_Problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy7NMIyKiiTE"
      },
      "source": [
        "#Roll No: J078\n",
        "\n",
        "#Neural Network Module - Traffic Problem\n",
        "\n",
        "Background\n",
        "\n",
        "As research continues in the development of self-driving cars, one of the key challenges is computer vision, allowing these cars to develop an understanding of their environment from digital images. In particular, this involves the ability to recognize and distinguish road signs – stop signs, speed limit signs, yield signs, and more.\n",
        "\n",
        "In this project, you’ll use TensorFlow to build a neural network to classify road signs based on an image of those signs. To do so, you’ll need a labeled dataset: a collection of images that have already been categorized by the road sign represented in them.\n",
        "\n",
        "Several such data sets exist, but for this project, we’ll use the German Traffic Sign Recognition Benchmark (GTSRB) dataset, which contains thousands of images of **43** different kinds of road signs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYs3Cg3IiXAF"
      },
      "source": [
        "\"\"\"\n",
        "Importing libraries cv2 for images \n",
        "\"\"\"\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\"\"\"\n",
        "Defining Epochs,\n",
        "Width & height of Image,\n",
        "Number of categories\n",
        "and Test Size\n",
        "\"\"\"\n",
        "EPOCHS = 50\n",
        "IMG_WIDTH = 30\n",
        "IMG_HEIGHT = 30\n",
        "NUM_CATEGORIES = 43\n",
        "TEST_SIZE = 0.4\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    # Check command-line arguments\n",
        "    if len(sys.argv) not in [2, 3]:\n",
        "        sys.exit(\"Usage: python traffic.py data_directory [model.h5]\")\n",
        "\n",
        "    # Get image arrays and labels for all image files\n",
        "    images, labels = load_data(sys.argv[1])\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    labels = tf.keras.utils.to_categorical(labels)\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        np.array(images), np.array(labels), test_size=TEST_SIZE\n",
        "    )\n",
        "\n",
        "    # Get a compiled neural network\n",
        "    model = get_model()\n",
        "\n",
        "    # Fit model on training data\n",
        "    model.fit(x_train, y_train, epochs=EPOCHS)\n",
        "\n",
        "    # Evaluate neural network performance\n",
        "    model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "    # Save model to file\n",
        "    if len(sys.argv) == 3:\n",
        "        filename = sys.argv[2]\n",
        "        model.save(filename)\n",
        "        print(f\"Model saved to {filename}.\")\n",
        "\n",
        "\n",
        "def load_data(data_dir):\n",
        "    \"\"\"\n",
        "    Load image data from directory `data_dir`.\n",
        "\n",
        "    Assume `data_dir` has one directory named after each category, numbered\n",
        "    0 through NUM_CATEGORIES - 1. Inside each category directory will be some\n",
        "    number of image files.\n",
        "\n",
        "    Return tuple `(images, labels)`. `images` should be a list of all\n",
        "    of the images in the data directory, where each image is formatted as a\n",
        "    numpy ndarray with dimensions IMG_WIDTH x IMG_HEIGHT x 3. `labels` should\n",
        "    be a list of integer labels, representing the categories for each of the\n",
        "    corresponding `images`.\n",
        "    \"\"\"\n",
        "    images = list()\n",
        "    labels = list()\n",
        "\n",
        "    for folder in os.listdir(data_dir):\n",
        "        folder_path = os.path.join(data_dir, folder)\n",
        "        if os.path.isdir(folder_path):\n",
        "            print(f\"Loading files from {folder_path}...\")\n",
        "            for file in os.listdir(folder_path):\n",
        "                try:\n",
        "                    image = cv2.imread(os.path.join(folder_path, file), cv2.IMREAD_COLOR)\n",
        "                    image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_AREA)\n",
        "                    images.append(image)\n",
        "                    labels.append(int(folder))\n",
        "                except Exception as e:\n",
        "                    print(f\"There is a problem with file: {file}\")\n",
        "                    print(str(e))\n",
        "\n",
        "    return images, labels\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    \"\"\"\n",
        "    Returns a compiled convolutional neural network model. Assume that the\n",
        "    `input_shape` of the first layer is `(IMG_WIDTH, IMG_HEIGHT, 3)`.\n",
        "    The output layer should have `NUM_CATEGORIES` units, one for each category.\n",
        "    \"\"\"\n",
        "        # Create a convolutional neural network\n",
        "    model = tf.keras.models.Sequential([\n",
        "\n",
        "        # Convolutional layer. Learn 32 filters using a 3x3 kernel\n",
        "        tf.keras.layers.Conv2D(\n",
        "            32, (3, 3), activation=\"relu\", input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)\n",
        "        ),\n",
        "\n",
        "        # Max-pooling layer, using 3x3 pool size\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(3, 3)),\n",
        "\n",
        "        # Flatten units\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "        # Add a hidden layer with dropout\n",
        "        tf.keras.layers.Dense(NUM_CATEGORIES * 32, activation=\"tanh\"),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "        # Add a hidden layer\n",
        "        tf.keras.layers.Dense(NUM_CATEGORIES * 16, activation=\"tanh\"),\n",
        "\n",
        "        # Add a hidden layer\n",
        "        tf.keras.layers.Dense(NUM_CATEGORIES * 8, activation=\"relu\"),\n",
        "\n",
        "        # Add an output layer with output units for all categories\n",
        "        tf.keras.layers.Dense(NUM_CATEGORIES, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    # Train neural network\n",
        "    model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oN8iVVHKkVyI"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}